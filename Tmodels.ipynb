{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "tFbJI-L0Sgow",
        "I7C1EQfveqOX",
        "SApTllks5SUA"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flXxn9-9P4Q7",
        "outputId": "2c8f4560-af64-4a4f-c591-3ffa33ef1728"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwkBbAvJ6AAL",
        "outputId": "d81f4148-58b7-4409-9056-14214cbcba51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.27.4-py3-none-any.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m86.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.7)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.13.4 tokenizers-0.13.3 transformers-4.27.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4G_5hEpPXVl"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "from sklearn.model_selection import cross_validate, cross_val_score, train_test_split\n",
        "from sklearn.linear_model import LogisticRegression, LinearRegression, Lasso, Ridge\n",
        "from sklearn.ensemble import AdaBoostRegressor, AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "\n",
        "\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "AllTextData = pd.read_csv('/content/drive/MyDrive/448 - Project/Tdata/AllTextData.csv')  \n",
        "TextAndNBA = pd.read_csv('/content/drive/MyDrive/448 - Project/Tdata/TextPlusNBA.csv')"
      ],
      "metadata": {
        "id": "lgXb3JjZQAm9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(AllTextData[AllTextData['year'] == 2021]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-DNQt7J_21R",
        "outputId": "86e1e45f-7c01-48d6-c807-5baa068cb36b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TextAndNBA[f\"AoBPR\"] = (TextAndNBA[\"PR\"] > TextAndNBA[\"PR\"].mean()).astype(int)"
      ],
      "metadata": {
        "id": "mE7VgVpPyfVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "TextAndNBA[\"AoBAvPR\"].hist()\n",
        "\n",
        "# show the histogram\n",
        "plt.show()\n",
        "\n",
        "\n",
        "TextAndNBA[\"AoBPTS\"].hist()\n",
        "\n",
        "# show the histogram\n",
        "plt.show()\n",
        "\n",
        "TextAndNBA[\"PTS\"].hist()\n",
        "\n",
        "# show the histogram\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cSaUyYIgxrLR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Performance = [\"FG%\", \"PR\", \"3P%\", \"PF\", \"PTS\"]"
      ],
      "metadata": {
        "id": "XjueUyZIHhnJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PercentTrain = 0.8\n",
        "np.random.seed(6)\n",
        "TrainIndex = np.random.choice(len(TextAndNBA),  int(len(TextAndNBA) * PercentTrain), replace=False)\n",
        "\n",
        "print(len(TextAndNBA))\n",
        "print(len(TextAndNBA.loc[TextAndNBA.index.isin(TrainIndex), 'removed_text']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtQYdY_fNHHQ",
        "outputId": "987198a1-04f3-4863-d17f-b122340658ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "271\n",
            "216\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sum(TextAndNBA['AoBPR'] / len(TextAndNBA))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ns7kqSagwGmV",
        "outputId": "6b8c35c6-10a3-48ea-86e9-de856ab2b95e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.516605166051661"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TF-IDF Unigram:"
      ],
      "metadata": {
        "id": "3O6RqyoWQUyc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_vectorizer = TfidfVectorizer(ngram_range =(1,1))\n",
        "\n",
        "# fit and transform the text data to calculate the TF-IDF unigram scores\n",
        "tfidf_unigrams = tfidf_vectorizer.fit_transform(TextAndNBA.loc[TextAndNBA.index.isin(TrainIndex), 'removed_text'])\n",
        "print(tfidf_unigrams.shape)\n",
        "\n",
        "# EXTRA BELOW:\n",
        "\n",
        "unigrams = tfidf_vectorizer.get_feature_names_out()\n",
        "\n",
        "\n",
        "# create a Pandas dataframe to store the TF-IDF unigram scores\n",
        "tfidf_unigram_df = pd.DataFrame(tfidf_unigrams.toarray(), columns=unigrams)"
      ],
      "metadata": {
        "id": "S01G3qhmSUs1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ef552de-820b-493d-ea86-9711e627f8da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(216, 2734)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = TfidfVectorizer(ngram_range =(1,1), min_df=2)\n",
        "\n",
        "# fit and transform the text data to calculate the TF-IDF unigram scores\n",
        "tfidf2_unigrams = df2.fit_transform(TextAndNBA.loc[TextAndNBA.index.isin(TrainIndex), 'removed_text'])\n",
        "print(tfidf2_unigrams.shape)\n",
        "\n",
        "df3 = TfidfVectorizer(ngram_range =(1,1), min_df=3)\n",
        "\n",
        "# fit and transform the text data to calculate the TF-IDF unigram scores\n",
        "tfidf3_unigrams = df3.fit_transform(TextAndNBA.loc[TextAndNBA.index.isin(TrainIndex), 'removed_text'])\n",
        "print(tfidf3_unigrams.shape)\n",
        "\n",
        "\n",
        "df4 = TfidfVectorizer(ngram_range =(1,1), min_df=4)\n",
        "\n",
        "# fit and transform the text data to calculate the TF-IDF unigram scores\n",
        "tfidf4_unigrams = df4.fit_transform(TextAndNBA.loc[TextAndNBA.index.isin(TrainIndex), 'removed_text'])\n",
        "print(tfidf4_unigrams.shape)\n",
        "\n",
        "\n",
        "df5 = TfidfVectorizer(ngram_range =(1,1), min_df=5)\n",
        "\n",
        "# fit and transform the text data to calculate the TF-IDF unigram scores\n",
        "tfidf5_unigrams = df5.fit_transform(TextAndNBA.loc[TextAndNBA.index.isin(TrainIndex), 'removed_text'])\n",
        "print(tfidf5_unigrams.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYoZEbTuA575",
        "outputId": "b42e4ad4-0af8-486a-cea2-d3f8bc0c761b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(216, 2333)\n",
            "(216, 1863)\n",
            "(216, 1495)\n",
            "(216, 1295)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For test data\n",
        "\n",
        "\n",
        "# fit and transform the text data to calculate the TF-IDF unigram scores\n",
        "tfidf_unigramsTest = tfidf_vectorizer.transform(TextAndNBA.loc[~TextAndNBA.index.isin(TrainIndex), 'removed_text'])\n",
        "print(tfidf_unigramsTest.shape)\n",
        "\n",
        "tfidf2_unigramsTest = df2.transform(TextAndNBA.loc[~TextAndNBA.index.isin(TrainIndex), 'removed_text'])\n",
        "\n",
        "tfidf3_unigramsTest = df3.transform(TextAndNBA.loc[~TextAndNBA.index.isin(TrainIndex), 'removed_text'])\n",
        "\n",
        "tfidf4_unigramsTest = df4.transform(TextAndNBA.loc[~TextAndNBA.index.isin(TrainIndex), 'removed_text'])\n",
        "\n",
        "tfidf5_unigramsTest = df5.transform(TextAndNBA.loc[~TextAndNBA.index.isin(TrainIndex), 'removed_text'])"
      ],
      "metadata": {
        "id": "k0dUVGBNSU5W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68d3a1de-18c9-4d3a-dcb0-671f5e5dcbb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(55, 2734)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TF-IDF Bigram:"
      ],
      "metadata": {
        "id": "LIT5OUe6SVC4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_vectorizer_bi = TfidfVectorizer(ngram_range =(2,2))\n",
        "\n",
        "# fit and transform the text data to calculate the TF-IDF unigram scores\n",
        "tfidf_bigrams = tfidf_vectorizer_bi.fit_transform(TextAndNBA.loc[TextAndNBA.index.isin(TrainIndex), 'removed_text'])\n",
        "print(tfidf_bigrams.shape)\n",
        "\n",
        "# EXTRA BELOW:\n",
        "\n",
        "# get the feature names (i.e., the unigrams)\n",
        "#x_array = \n",
        "#print(tfidf_unigrams.toarray())\n",
        "bigrams = tfidf_vectorizer_bi.get_feature_names_out()\n",
        "\n",
        "\n",
        "# create a Pandas dataframe to store the TF-IDF unigram scores\n",
        "tfidf_bigram_df = pd.DataFrame(tfidf_bigrams.toarray(), columns=bigrams)"
      ],
      "metadata": {
        "id": "2PO8ApNKSVMr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3beaaf5-826b-49e5-ec8b-560be9765be9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(216, 39904)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfb2 = TfidfVectorizer(ngram_range =(2,2), min_df=2)\n",
        "\n",
        "# fit and transform the text data to calculate the TF-IDF unigram scores\n",
        "tfidf2_bigrams = dfb2.fit_transform(TextAndNBA.loc[TextAndNBA.index.isin(TrainIndex), 'removed_text'])\n",
        "print(tfidf2_bigrams.shape)\n",
        "\n",
        "dfb3 = TfidfVectorizer(ngram_range =(2,2), min_df=3)\n",
        "\n",
        "# fit and transform the text data to calculate the TF-IDF unigram scores\n",
        "tfidf3_bigrams = dfb3.fit_transform(TextAndNBA.loc[TextAndNBA.index.isin(TrainIndex), 'removed_text'])\n",
        "print(tfidf3_bigrams.shape)\n",
        "\n",
        "\n",
        "dfb4 = TfidfVectorizer(ngram_range =(2,2), min_df=4)\n",
        "\n",
        "# fit and transform the text data to calculate the TF-IDF unigram scores\n",
        "tfidf4_bigrams = dfb4.fit_transform(TextAndNBA.loc[TextAndNBA.index.isin(TrainIndex), 'removed_text'])\n",
        "print(tfidf4_bigrams.shape)\n",
        "\n",
        "\n",
        "dfb5 = TfidfVectorizer(ngram_range =(2,2), min_df=5)\n",
        "\n",
        "# fit and transform the text data to calculate the TF-IDF unigram scores\n",
        "tfidf5_bigrams = dfb5.fit_transform(TextAndNBA.loc[TextAndNBA.index.isin(TrainIndex), 'removed_text'])\n",
        "print(tfidf5_bigrams.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_DUOHtEGzKR",
        "outputId": "cbfa4af5-3108-4738-f367-ae4b4fa5eaa7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(216, 7078)\n",
            "(216, 3042)\n",
            "(216, 1762)\n",
            "(216, 1160)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_bigramsTest = tfidf_vectorizer_bi.transform(TextAndNBA.loc[~TextAndNBA.index.isin(TrainIndex), 'removed_text'])\n",
        "print(tfidf_bigramsTest.shape)\n",
        "\n",
        "\n",
        "tfidf2_bigramsTest = dfb2.transform(TextAndNBA.loc[~TextAndNBA.index.isin(TrainIndex), 'removed_text'])\n",
        "\n",
        "tfidf3_bigramsTest = dfb3.transform(TextAndNBA.loc[~TextAndNBA.index.isin(TrainIndex), 'removed_text'])\n",
        "\n",
        "tfidf4_bigramsTest = dfb4.transform(TextAndNBA.loc[~TextAndNBA.index.isin(TrainIndex), 'removed_text'])\n",
        "\n",
        "tfidf5_bigramsTest = dfb5.transform(TextAndNBA.loc[~TextAndNBA.index.isin(TrainIndex), 'removed_text'])"
      ],
      "metadata": {
        "id": "HY8MWBAlSgcr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfeb29df-2244-4da8-b80c-f183b93ce653"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(55, 39904)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TD-IDF Uni and Bigrams"
      ],
      "metadata": {
        "id": "H_aA2fO1HrIa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_vectorizer_ubi = TfidfVectorizer(ngram_range =(1,2))\n",
        "\n",
        "# fit and transform the text data to calculate the TF-IDF unigram scores\n",
        "tfidf_ubigrams = tfidf_vectorizer_ubi.fit_transform(TextAndNBA.loc[TextAndNBA.index.isin(TrainIndex), 'removed_text'])\n",
        "print(tfidf_ubigrams.shape)\n",
        "\n",
        "# EXTRA BELOW:\n",
        "\n",
        "# get the feature names (i.e., the unigrams)\n",
        "#x_array = \n",
        "#print(tfidf_unigrams.toarray())\n",
        "ubigrams = tfidf_vectorizer_ubi.get_feature_names_out()\n",
        "\n",
        "\n",
        "# create a Pandas dataframe to store the TF-IDF unigram scores\n",
        "tfidf_ubigram_df = pd.DataFrame(tfidf_ubigrams.toarray(), columns=ubigrams)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1E2veoRDHzg4",
        "outputId": "504683fd-b5d8-45f8-8c7d-4d5b75a7ea5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(216, 42638)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfub2 = TfidfVectorizer(ngram_range =(1,2), min_df=2)\n",
        "\n",
        "# fit and transform the text data to calculate the TF-IDF unigram scores\n",
        "tfidf2_ubigrams = dfub2.fit_transform(TextAndNBA.loc[TextAndNBA.index.isin(TrainIndex), 'removed_text'])\n",
        "print(tfidf2_ubigrams.shape)\n",
        "\n",
        "dfub3 = TfidfVectorizer(ngram_range =(1,2), min_df=3)\n",
        "\n",
        "# fit and transform the text data to calculate the TF-IDF unigram scores\n",
        "tfidf3_ubigrams = dfub3.fit_transform(TextAndNBA.loc[TextAndNBA.index.isin(TrainIndex), 'removed_text'])\n",
        "print(tfidf3_ubigrams.shape)\n",
        "\n",
        "\n",
        "dfub4 = TfidfVectorizer(ngram_range =(1,2), min_df=4)\n",
        "\n",
        "# fit and transform the text data to calculate the TF-IDF unigram scores\n",
        "tfidf4_ubigrams = dfub4.fit_transform(TextAndNBA.loc[TextAndNBA.index.isin(TrainIndex), 'removed_text'])\n",
        "print(tfidf4_ubigrams.shape)\n",
        "\n",
        "\n",
        "dfub5 = TfidfVectorizer(ngram_range =(1,2), min_df=5)\n",
        "\n",
        "# fit and transform the text data to calculate the TF-IDF unigram scores\n",
        "tfidf5_ubigrams = dfub5.fit_transform(TextAndNBA.loc[TextAndNBA.index.isin(TrainIndex), 'removed_text'])\n",
        "print(tfidf5_ubigrams.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e3ctHXHHztx",
        "outputId": "7095d95c-0c4b-4143-9c82-92d3866ad284"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(216, 9411)\n",
            "(216, 4905)\n",
            "(216, 3257)\n",
            "(216, 2455)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_ubigramsTest = tfidf_vectorizer_ubi.transform(TextAndNBA.loc[~TextAndNBA.index.isin(TrainIndex), 'removed_text'])\n",
        "print(tfidf_ubigramsTest.shape)\n",
        "\n",
        "\n",
        "tfidf2_ubigramsTest = dfub2.transform(TextAndNBA.loc[~TextAndNBA.index.isin(TrainIndex), 'removed_text'])\n",
        "\n",
        "tfidf3_ubigramsTest = dfub3.transform(TextAndNBA.loc[~TextAndNBA.index.isin(TrainIndex), 'removed_text'])\n",
        "\n",
        "tfidf4_ubigramsTest = dfub4.transform(TextAndNBA.loc[~TextAndNBA.index.isin(TrainIndex), 'removed_text'])\n",
        "\n",
        "tfidf5_ubigramsTest = dfub5.transform(TextAndNBA.loc[~TextAndNBA.index.isin(TrainIndex), 'removed_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nNjeQwOH0jN",
        "outputId": "355b9ac0-521b-4d7a-a6a6-75d3be5c1ab4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(55, 42638)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word2vec:"
      ],
      "metadata": {
        "id": "tFbJI-L0Sgow"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_data = TextAndNBA.loc[TextAndNBA.index.isin(TrainIndex), 'removed_text'].values.tolist()\n",
        "tokenized_data = [text.split() for text in text_data]\n",
        "VECTOR_SIZE = 60\n",
        "model = Word2Vec(tokenized_data, min_count=3, vector_size=VECTOR_SIZE)\n",
        "embedded_data = []\n",
        "for text in tokenized_data:\n",
        "    embedded_text = [model.wv[word] for word in text if word in model.wv.key_to_index]\n",
        "    embedded_data.append(embedded_text)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "z0l1auUNSg08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lengts = np.empty(0)\n",
        "for text in embedded_data:\n",
        "  lengts = np.append(lengts, len(text))\n",
        "\n",
        "print(lengts.max())\n",
        "print(lengts.min())\n",
        "MAXWORDS = int(lengts.max())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrofdSeZr06h",
        "outputId": "e5cadb64-7b99-4a9d-ae60-9eecd5962cd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "798.0\n",
            "9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word2vec_embed = np.empty((0,MAXWORDS,VECTOR_SIZE))\n",
        "for document in embedded_data:\n",
        "  doc_vec = np.empty((0, VECTOR_SIZE))\n",
        "  for word in document:\n",
        "\n",
        "    doc_vec = np.vstack((doc_vec, np.reshape(word, (1, VECTOR_SIZE))))\n",
        "\n",
        "  if doc_vec.shape[0] < MAXWORDS:\n",
        "    n = MAXWORDS - doc_vec.shape[0]\n",
        "    doc_vec = np.pad(doc_vec, [(0, n), (0 , 0)], mode = 'constant')\n",
        "    \n",
        "  elif doc_vec.shape[0] > MAXWORDS:\n",
        "    doc_vec = doc_vec[:MAXWORDS, :]\n",
        "\n",
        "  \n",
        "\n",
        "  word2vec_embed = np.vstack((word2vec_embed, np.reshape(doc_vec, (1, MAXWORDS, VECTOR_SIZE))))"
      ],
      "metadata": {
        "id": "gBe9D-OVnHRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "word2vec_embed = np.reshape(word2vec_embed, (word2vec_embed.shape[0],  word2vec_embed.shape[1] * word2vec_embed.shape[2]   ))\n",
        "print(word2vec_embed.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ve8_gWWAssow",
        "outputId": "3f496661-3b25-40e0-9f57-1a29b241e0e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(216, 47880)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_data = TextAndNBA.loc[~TextAndNBA.index.isin(TrainIndex), 'removed_text'].values.tolist()\n",
        "tokenized_data = [text.split() for text in text_data]\n",
        "model = Word2Vec(tokenized_data, min_count=3, vector_size=VECTOR_SIZE)\n",
        "embedded_data = []\n",
        "for text in tokenized_data:\n",
        "    embedded_text = [model.wv[word] for word in text if word in model.wv.key_to_index]\n",
        "    embedded_data.append(embedded_text)\n",
        "\n",
        "\n",
        "word2vec_embedTest = np.empty((0,MAXWORDS,VECTOR_SIZE))\n",
        "for document in embedded_data:\n",
        "  doc_vec = np.empty((0, VECTOR_SIZE))\n",
        "  for word in document:\n",
        "\n",
        "    doc_vec = np.vstack((doc_vec, np.reshape(word, (1, VECTOR_SIZE))))\n",
        "\n",
        "  if doc_vec.shape[0] < MAXWORDS:\n",
        "    n = MAXWORDS - doc_vec.shape[0]\n",
        "    doc_vec = np.pad(doc_vec, [(0, n), (0 , 0)], mode = 'constant')\n",
        "    \n",
        "  elif doc_vec.shape[0] > MAXWORDS:\n",
        "    doc_vec = doc_vec[:MAXWORDS, :]\n",
        "\n",
        "  \n",
        "\n",
        "  word2vec_embedTest = np.vstack((word2vec_embedTest, np.reshape(doc_vec, (1, MAXWORDS, VECTOR_SIZE))))\n",
        "\n",
        "\n",
        "\n",
        "word2vec_embedTest = np.reshape(word2vec_embedTest, (word2vec_embedTest.shape[0],  word2vec_embedTest.shape[1] * word2vec_embedTest.shape[2]   ))\n",
        "print(word2vec_embedTest.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKErdSCWq0s0",
        "outputId": "d4d6836b-6c6a-480f-c764-8f45fe684519"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(55, 47880)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing word2vec models"
      ],
      "metadata": {
        "id": "I7C1EQfveqOX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = big_vec\n",
        "#print(X)\n",
        "y = np.array(TextAndNBA.loc[TextAndNBA.index.isin(TrainIndex), 'AoBPR'])\n",
        "\n",
        "# Split the data into training and test sets\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "#print(X_train.shape)\n",
        "# Train the logistic regression model\n",
        "\n",
        "#print(X_train.shape)\n",
        "\n",
        "logmodel = LogisticRegression(penalty='l1',max_iter=300, solver='liblinear')\n",
        "logmodel.fit(X, y)\n",
        "\n",
        "# Evaluate the model\n",
        "#y_pred = model.predict(X_test)\n",
        "\n",
        "#accuracy = (y_pred == y_test).mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "Qo-oBg1mS38I",
        "outputId": "6016fb54-2ca7-46be-8f82-f99126a46ee0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(max_iter=300, penalty='l1', solver='liblinear')"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=300, penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=300, penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lqCOA8lnu7kF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for perf in Performance:\n",
        "  # Extract the tf-idf scores and the AoBPR label from your dataframe\n",
        "  X = big_vec\n",
        "  y = TextAndNBA[f\"AoB{perf}\"][TrainIndex].values\n",
        "  print(f\"For perf: {perf}\")\n",
        "  # Split the data into training and testing sets\n",
        "  \n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "  # Create an instance of the logistic regression model\n",
        "  logreg = LogisticRegression(penalty='l1',max_iter=300, solver='liblinear')\n",
        "\n",
        "  # Fit the model to the training data\n",
        "  #logreg.fit(X_train, y_train)\n",
        "\n",
        "  # Predict the labels for the test data\n",
        "  #y_pred = logreg.predict(X_test)\n",
        "\n",
        "  scores = cross_val_score(logreg, X, y, cv=10)\n",
        "\n",
        " \n",
        "\n",
        "  print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKNsw3TTZ4Pu",
        "outputId": "f4578af0-1415-4907-8553-e32bb1a73829"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For perf: FG%\n",
            "Accuracy: 0.48 (+/- 0.25)\n",
            "For perf: PR\n",
            "Accuracy: 0.65 (+/- 0.21)\n",
            "For perf: 3P%\n",
            "Accuracy: 0.40 (+/- 0.21)\n",
            "For perf: PF\n",
            "Accuracy: 0.50 (+/- 0.17)\n",
            "For perf: PTS\n",
            "Accuracy: 0.56 (+/- 0.16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_data = TextAndNBA.loc[~TextAndNBA.index.isin(TrainIndex), 'removed_text'].values.tolist()\n",
        "tokenized_data = [text.split() for text in text_data]\n",
        "VECTOR_SIZE = 50\n",
        "model = Word2Vec(tokenized_data, min_count=3, vector_size=VECTOR_SIZE)\n",
        "embedded_data = []\n",
        "for text in tokenized_data:\n",
        "    embedded_text = [model.wv[word] for word in text if word in model.wv.key_to_index]\n",
        "    embedded_data.append(embedded_text)\n",
        "\n",
        "\n",
        "big_vec = np.empty((0,MAXWORDS,VECTOR_SIZE))\n",
        "for document in embedded_data:\n",
        "  doc_vec = np.empty((0, VECTOR_SIZE))\n",
        "  for word in document:\n",
        "\n",
        "    doc_vec = np.vstack((doc_vec, np.reshape(word, (1, VECTOR_SIZE))))\n",
        "\n",
        "  if doc_vec.shape[0] < MAXWORDS:\n",
        "    n = MAXWORDS - doc_vec.shape[0]\n",
        "    doc_vec = np.pad(doc_vec, [(0, n), (0 , 0)], mode = 'constant')\n",
        "    \n",
        "  elif doc_vec.shape[0] > MAXWORDS:\n",
        "    doc_vec = doc_vec[:MAXWORDS, :]\n",
        "\n",
        "  \n",
        "\n",
        "  big_vec = np.vstack((big_vec, np.reshape(doc_vec, (1, MAXWORDS, VECTOR_SIZE))))\n",
        "\n",
        "\n",
        "print(np.reshape(big_vec, (big_vec.shape[0],  big_vec.shape[1] * big_vec.shape[2]   )).shape)\n",
        "big_vec = np.reshape(big_vec, (big_vec.shape[0],  big_vec.shape[1] * big_vec.shape[2]   ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qe4JF7v-U3GT",
        "outputId": "f2cf0b77-25f4-4d49-c846-8872f5e1ead8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(55, 39900)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = big_vec\n",
        "\n",
        "#for perf in Performance:\n",
        "\n",
        "y_test = TextAndNBA.loc[~TextAndNBA.index.isin(TrainIndex), f'AoBPR']\n",
        "\n",
        "\n",
        "y_pred = logmodel.predict(X_test)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "accuracy = (y_pred == y_test).mean()\n",
        "print(f\"Test {perf} accuracy: {accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Db60M0LNTnwP",
        "outputId": "5aa7b46c-8942-486b-b9e5-13c28154ccc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test FG% accuracy: 0.6181818181818182\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vec_range = [20, 40, 60, 80, 100, 120]\n",
        "\n",
        "for VECTOR_SIZE in vec_range:\n",
        "  print(f\"ATTEMPTING VECTOR SIZE {VECTOR_SIZE}\")\n",
        "  model = Word2Vec(tokenized_data, min_count=3, vector_size=VECTOR_SIZE)\n",
        "  embedded_data = []\n",
        "  for text in tokenized_data:\n",
        "      embedded_text = [model.wv[word] for word in text if word in model.wv.key_to_index]\n",
        "      embedded_data.append(embedded_text)\n",
        "  lengts = np.empty(0)\n",
        "  for text in embedded_data:\n",
        "    lengts = np.append(lengts, len(text))\n",
        "\n",
        "\n",
        "\n",
        "  big_vec = np.empty((0,MAXWORDS,VECTOR_SIZE))\n",
        "  for document in embedded_data:\n",
        "    doc_vec = np.empty((0, VECTOR_SIZE))\n",
        "    for word in document:\n",
        "      doc_vec = np.vstack((doc_vec, np.reshape(word, (1, VECTOR_SIZE))))\n",
        "    if doc_vec.shape[0] < MAXWORDS:\n",
        "      n = MAXWORDS - doc_vec.shape[0]\n",
        "      doc_vec = np.pad(doc_vec, [(0, n), (0 , 0)], mode = 'constant')\n",
        "    big_vec = np.vstack((big_vec, np.reshape(doc_vec, (1, MAXWORDS, VECTOR_SIZE))))\n",
        "  big_vec = np.reshape(big_vec, (big_vec.shape[0],  big_vec.shape[1] * big_vec.shape[2]   ))\n",
        "\n",
        "\n",
        "\n",
        "  for perf in Performance:\n",
        "    # Extract the tf-idf scores and the AoBPR label from your dataframe\n",
        "    X = big_vec\n",
        "    y = TextAndNBA[f\"AoB{perf}\"].values\n",
        "    print(f\"For perf: {perf}\")\n",
        "    # Split the data into training and testing sets\n",
        "    \n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Create an instance of the logistic regression model\n",
        "    logreg = LogisticRegression(penalty='l1',max_iter=300, solver='liblinear')\n",
        "\n",
        "    # Fit the model to the training data\n",
        "    #logreg.fit(X_train, y_train)\n",
        "\n",
        "    # Predict the labels for the test data\n",
        "    #y_pred = logreg.predict(X_test)\n",
        "\n",
        "    scores = cross_val_score(logreg, X, y, cv=10)\n",
        "\n",
        "  \n",
        "\n",
        "    print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n"
      ],
      "metadata": {
        "id": "ByVx2OS22g4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BERT Vectorization"
      ],
      "metadata": {
        "id": "SApTllks5SUA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "## TAKES AROUND 10 MINUTES\n",
        "\n",
        "\n",
        "# Load text data from pandas DataFrame\n",
        "texts = TextAndNBA.loc[TextAndNBA.index.isin(TrainIndex), 'removed_text'].tolist()\n",
        "\n",
        "# Tokenize text using BERT tokenizer\n",
        "tokens = tokenizer.batch_encode_plus(texts,\n",
        "                                      add_special_tokens=True,\n",
        "                                      padding=True,\n",
        "                                      truncation=True,\n",
        "                                      return_tensors='pt')\n",
        "\n",
        "# Generate BERT embeddings for the input text\n",
        "with torch.no_grad():\n",
        "    embeddings = model(tokens['input_ids'], attention_mask=tokens['attention_mask'])[0]\n",
        "\n",
        "# Extract the embeddings for the first token (the [CLS] token)\n",
        "bert_embeddings = embeddings[:, 0, :].numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGZopxaU5TqY",
        "outputId": "aa863927-cabe-4dd3-f541-4784b327013e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(bert_embeddings.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hiqgo_vR5Skb",
        "outputId": "60852c04-e48f-42d3-daeb-9e28cd4c27fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(216, 768)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts = TextAndNBA.loc[~TextAndNBA.index.isin(TrainIndex), 'removed_text'].tolist()\n",
        "\n",
        "# Tokenize text using BERT tokenizer\n",
        "tokens = tokenizer.batch_encode_plus(texts,\n",
        "                                      add_special_tokens=True,\n",
        "                                      padding=True,\n",
        "                                      truncation=True,\n",
        "                                      return_tensors='pt')\n",
        "\n",
        "# Generate BERT embeddings for the input text\n",
        "with torch.no_grad():\n",
        "    embeddings = model(tokens['input_ids'], attention_mask=tokens['attention_mask'])[0]\n",
        "\n",
        "# Extract the embeddings for the first token (the [CLS] token)\n",
        "bert_embeddingsTest = embeddings[:, 0, :].numpy()\n",
        "print(bert_embeddingsTest.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDMkfSpMsIHn",
        "outputId": "96d67ef4-60ac-4529-aa75-5703cad7eb69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(55, 768)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing BERT Data"
      ],
      "metadata": {
        "id": "XP5Twfn7fAtJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.save(\"/content/drive/MyDrive/448 - Project/Tdata/BERTEmbeddings.npy\")"
      ],
      "metadata": {
        "id": "5EcDoYLFGKyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = bert_embeddings\n",
        "#print(X)\n",
        "y = np.array(TextAndNBA['AoBPR'])\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "#print(X_train.shape)\n",
        "# Train the logistic regression model\n",
        "\n",
        "print(X_train.shape)\n",
        "\n",
        "model = LogisticRegression(penalty='l1',max_iter=300, solver='liblinear')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "accuracy = (y_pred == y_test).mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIIGjqBRFgDP",
        "outputId": "5b209bfd-0dc8-4f7f-a1d9-9ac7159eda8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(216, 768)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for perf in Performance:\n",
        "  # Extract the tf-idf scores and the AoBPR label from your dataframe\n",
        "  X = bert_embeddings\n",
        "  y = TextAndNBA[f\"AoB{perf}\"].values\n",
        "  print(f\"For perf: {perf}\")\n",
        "  # Split the data into training and testing sets\n",
        "  \n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "  # Create an instance of the logistic regression model\n",
        "  logreg = LogisticRegression(penalty='l1',max_iter=300, solver='liblinear')\n",
        "\n",
        "  # Fit the model to the training data\n",
        "  #logreg.fit(X_train, y_train)\n",
        "\n",
        "  # Predict the labels for the test data\n",
        "  #y_pred = logreg.predict(X_test)\n",
        "\n",
        "  scores = cross_val_score(logreg, X, y, cv=10)\n",
        "\n",
        " \n",
        "\n",
        "  print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_KOPW_TFppZ",
        "outputId": "890f7608-2a76-4c0b-c85a-572f740514d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For perf: FG%\n",
            "Accuracy: 0.51 (+/- 0.15)\n",
            "For perf: PR\n",
            "Accuracy: 0.68 (+/- 0.10)\n",
            "For perf: 3P%\n",
            "Accuracy: 0.54 (+/- 0.18)\n",
            "For perf: PF\n",
            "Accuracy: 0.57 (+/- 0.17)\n",
            "For perf: PTS\n",
            "Accuracy: 0.46 (+/- 0.12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models"
      ],
      "metadata": {
        "id": "ol-0p4J7B5YA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Digging into tfidf"
      ],
      "metadata": {
        "id": "R98HFyEXB-If"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ALL_DATA = {\"unigram_tfidf\": tfidf_unigrams, \"unigram_tfidf2\": tfidf2_unigrams, \"unigram_tfidf3\": tfidf3_unigrams, \"unigram_tfidf4\": tfidf4_unigrams, \"unigram_tfidf5\": tfidf5_unigrams,\n",
        "            \"bigram_tfidf\": tfidf_bigrams, \"bigram_tfidf2\": tfidf2_bigrams, \"bigram_tfidf3\": tfidf3_bigrams, \"bigram_tfidf4\": tfidf4_bigrams, \"bigram_tfidf5\": tfidf5_bigrams,\n",
        "            \"ubigram_tfidf\": tfidf_ubigrams, \"ubigram_tfidf2\": tfidf2_ubigrams, \"ubigram_tfidf3\": tfidf3_ubigrams, \"ubigram_tfidf4\": tfidf4_ubigrams, \"ubigram_tfidf5\": tfidf5_ubigrams,\n",
        "            \"word2vec\": word2vec_embed, \"bert_embeddings\": bert_embeddings}\n",
        "ALL_TEST = {\"unigram_tfidf\": tfidf_unigramsTest, \"unigram_tfidf2\": tfidf2_unigramsTest, \"unigram_tfidf3\": tfidf3_unigramsTest, \"unigram_tfidf4\": tfidf4_unigramsTest, \"unigram_tfidf5\": tfidf5_unigramsTest,\n",
        "            \"bigram_tfidf\": tfidf_bigramsTest, \"bigram_tfidf2\": tfidf2_bigramsTest, \"bigram_tfidf3\": tfidf3_bigramsTest, \"bigram_tfidf4\": tfidf4_bigramsTest, \"bigram_tfidf5\": tfidf5_bigramsTest,\n",
        "            \"ubigram_tfidf\": tfidf_ubigramsTest, \"ubigram_tfidf2\": tfidf2_ubigramsTest, \"ubigram_tfidf3\": tfidf3_ubigramsTest, \"ubigram_tfidf4\": tfidf4_ubigramsTest, \"ubigram_tfidf5\": tfidf5_ubigramsTest,\n",
        "            \"word2vec\": word2vec_embedTest, \"bert_embeddings\": bert_embeddingsTest}"
      ],
      "metadata": {
        "id": "TEtsYwD5CUHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2W8bukG2CUU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Model\n"
      ],
      "metadata": {
        "id": "AQeQKgvSmksg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remember: Data is tfidf_unigrams for unigram tfidf, tfidf_bigrams for bigram tfidf, word2vec_embed for word2vec, bert_embeddings for BERT. All of the testing data is the same as train + Test"
      ],
      "metadata": {
        "id": "cRlthyePgy3C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ALL_DATA = {\"unigram_tfidf\": tfidf_unigrams, \"bigram_tfidf\": tfidf_bigrams, \"word2vec\": word2vec_embed, \"bert_embeddings\": bert_embeddings}\n",
        "ALL_TEST = {\"unigram_tfidf\": tfidf_unigramsTest, \"bigram_tfidf\": tfidf_bigramsTest, \"word2vec\": word2vec_embedTest, \"bert_embeddings\": bert_embeddingsTest}"
      ],
      "metadata": {
        "id": "Q4-BOf4-0CAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = TextAndNBA[f\"AoBPR\"][TrainIndex].values\n",
        "\n",
        "X = bert_embeddings\n",
        "\n",
        "\n",
        "\n",
        "logreg = LogisticRegression(penalty='l1',max_iter=300, solver='liblinear')\n",
        "\n",
        "\n",
        "# Fit the model to the training data\n",
        "#logreg.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels for the test data\n",
        "#y_pred = logreg.predict(X_test)\n",
        "\n",
        "scores = cross_validate(logreg, X, y, cv=10, return_estimator=True)"
      ],
      "metadata": {
        "id": "uWVCvW6Cmk4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(scores['estimator'][4].predict(X))\n",
        "print(scores['test_score'].mean())\n",
        "np.argmax(scores['test_score'])"
      ],
      "metadata": {
        "id": "YDMj4VnBmlFK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae65f30c-ca9d-4e88-b523-182e4334163b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 1 1 1 1 1 0 0 0 0 0 1 0 1 0 1 1 1 1 0 1 0 1 0 0 0 1 1 1 1 0 1 0 1 1 0\n",
            " 1 1 0 0 0 1 0 1 0 1 1 1 0 0 0 1 0 1 0 1 1 1 1 0 0 0 0 1 1 1 1 0 1 0 1 0 1\n",
            " 0 1 1 1 0 0 0 0 0 1 1 0 0 1 0 0 1 1 0 0 0 1 1 1 0 1 1 1 0 1 0 1 0 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0 0 1 1 1 0 1 1 0 1 0 0 1 1 0 0 1 1\n",
            " 0 0 0 0 1 0 1 0 1 1 0 1 1 1 0 1 1 1 0 1 0 0 1 0 1 0 1 0 1 1 1 1 1 1 0 1 1\n",
            " 1 0 1 0 1 1 0 1 0 0 0 0 1 1 1 1 0 0 1 1 0 1 1 1 1 0 1 1 1 1 1]\n",
            "0.4404761904761905\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "perf_bests = []\n",
        "perf_models = []\n",
        "perf_model_names = []\n",
        "\n",
        "for perf in Performance:\n",
        "  y = TextAndNBA.loc[TextAndNBA.index.isin(TrainIndex), f'AoB{perf}'].values\n",
        "  best_performance = 0\n",
        "  best_scores = None\n",
        "  best_embedding = \"\"\n",
        "  for embeddingType in ALL_DATA.keys():\n",
        "    X = ALL_DATA[embeddingType]\n",
        "    logreg = LogisticRegression(penalty='l1',max_iter=300, solver='liblinear')\n",
        "    scores = cross_validate(logreg, X, y, cv=10, return_estimator=True)\n",
        "    mean_performance = scores['test_score'].mean()\n",
        "    if mean_performance > best_performance:\n",
        "      best_performance = mean_performance\n",
        "      best_scores = scores\n",
        "      best_embedding = embeddingType\n",
        "\n",
        "  print(f\"Best performance for AoB{perf}: {best_performance}\")\n",
        "  print(f\"Used model {best_embedding}\")\n",
        "\n",
        "  \n",
        "  bestModelIndex = np.argmax(best_scores['test_score'])\n",
        "  perf_bests.append(best_performance)\n",
        "  perf_models.append(best_scores[\"estimator\"][bestModelIndex])\n",
        "  perf_model_names.append(best_embedding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JNKHInXz9YX",
        "outputId": "147b74d8-580c-400f-ddd1-e78c16a40998"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best performance for AoBFG%: 0.5372294372294372\n",
            "Used model word2vec\n",
            "Best performance for AoBPR: 0.5783549783549784\n",
            "Used model bigram_tfidf4\n",
            "Best performance for AoB3P%: 0.5415584415584416\n",
            "Used model bert_embeddings\n",
            "Best performance for AoBPF: 0.58008658008658\n",
            "Used model bert_embeddings\n",
            "Best performance for AoBPTS: 0.5413419913419913\n",
            "Used model word2vec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for performanceIndex, perf in enumerate(Performance):\n",
        "  y_test = TextAndNBA.loc[~TextAndNBA.index.isin(TrainIndex), f'AoB{perf}'].values\n",
        "  embedding = perf_model_names[performanceIndex]\n",
        "  X_test = ALL_TEST[embedding]\n",
        "  current_model = perf_models[performanceIndex]\n",
        "  y_pred = current_model.predict(X_test)\n",
        "  accuracy = (y_pred == y_test).mean()\n",
        "  print(f\"Using {embedding}, the test accuracy for AoB{perf} was: {accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGn3V3LS3sMa",
        "outputId": "d6bf4cab-8f1a-457b-a779-f9aaa5ffd0bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using word2vec, the test accuracy for AoBFG% was: 0.43636363636363634\n",
            "Using unigram_tfidf, the test accuracy for AoBPR was: 0.5272727272727272\n",
            "Using bert_embeddings, the test accuracy for AoB3P% was: 0.5818181818181818\n",
            "Using bert_embeddings, the test accuracy for AoBPF was: 0.5818181818181818\n",
            "Using word2vec, the test accuracy for AoBPTS was: 0.509090909090909\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AdaBoost Classifier"
      ],
      "metadata": {
        "id": "-8LlStLWJiQi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "array = np.arange(1, 101, 4)\n",
        "print(array)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--L7-VXBXQXh",
        "outputId": "5cb63dad-1cbb-45fc-a2ba-5cfe9f168371"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1  5  9 13 17 21 25 29 33 37 41 45 49 53 57 61 65 69 73 77 81 85 89 93\n",
            " 97]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "perf_bests = []\n",
        "perf_models = []\n",
        "perf_model_names = []\n",
        "num_estimators = list(range(0, 111, 5))\n",
        "num_estimators[0] = 1\n",
        "\n",
        "best_estimators = []\n",
        "best_features = []\n",
        "\n",
        "\n",
        "num_features = [\"sqrt\", \"log2\", \"special\", \"auto\"]\n",
        "\n",
        "for perf in Performance:\n",
        "  y = TextAndNBA.loc[TextAndNBA.index.isin(TrainIndex), f'AoB{perf}'].values\n",
        "  best_performance = 0\n",
        "  best_scores = None\n",
        "  best_embedding = \"\"\n",
        "  best_esti = 0\n",
        "  best_feature = None\n",
        "\n",
        "  for num_feature in num_features:\n",
        "    for num_estimator in num_estimators:\n",
        "      for embeddingType in ALL_DATA.keys():\n",
        "        X = ALL_DATA[embeddingType]\n",
        "\n",
        "        if num_feature == \"special\":\n",
        "          num_feature = int(X.shape[1] / 3)\n",
        "\n",
        "        sample_tree = DecisionTreeClassifier(max_features=num_feature)\n",
        "        adareg = AdaBoostClassifier(estimator = sample_tree, n_estimators= num_estimator)\n",
        "        scores = cross_validate(adareg, X, y, cv=10, return_estimator=True)\n",
        "        mean_performance = scores['test_score'].mean()\n",
        "        if mean_performance > best_performance:\n",
        "          best_performance = mean_performance\n",
        "          best_scores = scores\n",
        "          best_embedding = embeddingType\n",
        "          best_esti = num_estimator\n",
        "          best_feature = num_feature\n",
        "  print(f\"Best performance for AoB{perf}: {best_performance}\")\n",
        "  print(f\"Used model {best_embedding}\")\n",
        "  print(f\"Best Estimator {best_esti}\")\n",
        "  print(f\"Best Feature {best_feature}\")\n",
        "\n",
        "\n",
        "  best_features.append(best_feature)\n",
        "  best_estimators.append(best_esti)\n",
        "  bestModelIndex = np.argmax(best_scores['test_score'])\n",
        "  perf_bests.append(best_performance)\n",
        "  perf_models.append(best_scores[\"estimator\"][bestModelIndex])\n",
        "  perf_model_names.append(best_embedding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TL5fczAuJiwD",
        "outputId": "fd549dab-e40c-45dc-8d67-7c7f1a808a5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best performance for AoBFG%: 0.629004329004329\n",
            "Used model bigram_tfidf\n",
            "Best Estimator 95\n",
            "Best Feature auto\n",
            "Best performance for AoBPR: 0.620995670995671\n",
            "Used model bigram_tfidf3\n",
            "Best Estimator 90\n",
            "Best Feature log2\n",
            "Best performance for AoB3P%: 0.6158008658008659\n",
            "Used model unigram_tfidf\n",
            "Best Estimator 25\n",
            "Best Feature log2\n",
            "Best performance for AoBPF: 0.6298701298701298\n",
            "Used model unigram_tfidf4\n",
            "Best Estimator 60\n",
            "Best Feature auto\n",
            "Best performance for AoBPTS: 0.6153679653679653\n",
            "Used model ubigram_tfidf2\n",
            "Best Estimator 60\n",
            "Best Feature sqrt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Linear Regression"
      ],
      "metadata": {
        "id": "ipViIHlOmrbp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "perf_bests = []\n",
        "perf_models = []\n",
        "perf_model_names = []\n",
        "\n",
        "for perf in Performance:\n",
        "  y = TextAndNBA.loc[TextAndNBA.index.isin(TrainIndex), f'{perf}'].values\n",
        "  best_performance = -100000000\n",
        "  best_scores = None\n",
        "  best_embedding = \"\"\n",
        "  for embeddingType in ALL_DATA.keys():\n",
        "    X = ALL_DATA[embeddingType]\n",
        "    linreg = LinearRegression()\n",
        "    scores = cross_validate(linreg, X, y, cv=10, return_estimator=True)\n",
        "    mean_performance = scores['test_score'].mean()\n",
        "    if mean_performance > best_performance:\n",
        "      best_performance = mean_performance\n",
        "      best_scores = scores\n",
        "      best_embedding = embeddingType\n",
        "\n",
        "  print(f\"Best performance for {perf}: {best_performance}\")\n",
        "  print(f\"Used model {best_embedding}\")\n",
        "\n",
        "  \n",
        "  bestModelIndex = np.argmax(best_scores['test_score'])\n",
        "  perf_bests.append(best_performance)\n",
        "  perf_models.append(best_scores[\"estimator\"][bestModelIndex])\n",
        "  perf_model_names.append(best_embedding)"
      ],
      "metadata": {
        "id": "4TD5fS9amrmt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f34deb23-3abe-4e4c-d498-0935cca78def"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best performance for FG%: -0.004028617141769298\n",
            "Used model ubigram_tfidf\n",
            "Best performance for PR: -0.07993629488252481\n",
            "Used model bigram_tfidf3\n",
            "Best performance for 3P%: -0.12407974067662693\n",
            "Used model bigram_tfidf3\n",
            "Best performance for PF: -0.0011694626468689018\n",
            "Used model ubigram_tfidf\n",
            "Best performance for PTS: 0.02605813391234768\n",
            "Used model ubigram_tfidf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lasso regression"
      ],
      "metadata": {
        "id": "h6LX7gp8mlSi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "perf_bests = []\n",
        "perf_models = []\n",
        "perf_model_names = []\n",
        "perf_alphas = []\n",
        "for perf in Performance:\n",
        "  y = TextAndNBA.loc[TextAndNBA.index.isin(TrainIndex), f'{perf}'].values\n",
        "  best_performance = -100000000\n",
        "  best_scores = None\n",
        "  best_embedding = \"\"\n",
        "  best_alpha = 0\n",
        "  alpha_values = [ 1e-1, 0.5, 1]\n",
        "  for alpha in alpha_values:\n",
        "    for embeddingType in ALL_DATA.keys():\n",
        "      X = ALL_DATA[embeddingType]\n",
        "      lassoreg = Lasso(alpha, max_iter=3000)\n",
        "      scores = cross_validate(lassoreg, X, y, cv=10, return_estimator=True)\n",
        "      mean_performance = scores['test_score'].mean()\n",
        "      if mean_performance > best_performance:\n",
        "        best_performance = mean_performance\n",
        "        best_scores = scores\n",
        "        best_embedding = embeddingType\n",
        "        best_alpha = alpha\n",
        "  print(f\"Best performance for {perf}: {best_performance}\")\n",
        "  print(f\"Used model {best_embedding}\")\n",
        "  print(f\"Used alpha {best_alpha}\")\n",
        "  \n",
        "  bestModelIndex = np.argmax(best_scores['test_score'])\n",
        "  perf_bests.append(best_performance)\n",
        "  perf_models.append(best_scores[\"estimator\"][bestModelIndex])\n",
        "  perf_model_names.append(best_embedding)\n",
        "  perf_alphas.append(best_alpha)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upAKLKlf8lBC",
        "outputId": "b28df744-c7b7-4ee7-9119-8d5ab6399704"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best performance for FG%: -0.013075493055539478\n",
            "Used model unigram_tfidf\n",
            "Used alpha 0.1\n",
            "Best performance for PR: -0.1881234228836522\n",
            "Used model bert_embeddings\n",
            "Used alpha 0.1\n",
            "Best performance for 3P%: -0.15393448275947347\n",
            "Used model unigram_tfidf3\n",
            "Used alpha 0.1\n",
            "Best performance for PF: -0.016085247399239576\n",
            "Used model bert_embeddings\n",
            "Used alpha 0.1\n",
            "Best performance for PTS: -0.016448075460353352\n",
            "Used model word2vec\n",
            "Used alpha 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ridge Regression"
      ],
      "metadata": {
        "id": "MI2UcKLBJKgT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "perf_bests = []\n",
        "perf_models = []\n",
        "perf_model_names = []\n",
        "perf_alphas = []\n",
        "for perf in Performance:\n",
        "  y = TextAndNBA.loc[TextAndNBA.index.isin(TrainIndex), f'{perf}'].values\n",
        "  best_performance = -100000000\n",
        "  best_scores = None\n",
        "  best_embedding = \"\"\n",
        "  best_alpha = 0\n",
        "  alpha_values = [1e-3, 5e-2, 1e-2, 1e-1, 0.5, 1, 5, 10, 50, 100]\n",
        "  for alpha in alpha_values:\n",
        "    for embeddingType in ALL_DATA.keys():\n",
        "      X = ALL_DATA[embeddingType]\n",
        "      ridgereg = Ridge(alpha, max_iter=3000)\n",
        "      scores = cross_validate(ridgereg, X, y, cv=10, return_estimator=True)\n",
        "      mean_performance = scores['test_score'].mean()\n",
        "      if mean_performance > best_performance:\n",
        "        best_performance = mean_performance\n",
        "        best_scores = scores\n",
        "        best_embedding = embeddingType\n",
        "        best_alpha = alpha\n",
        "  print(f\"Best performance for {perf}: {best_performance}\")\n",
        "  print(f\"Used model {best_embedding}\")\n",
        "  print(f\"Used alpha {best_alpha}\")\n",
        "  \n",
        "  bestModelIndex = np.argmax(best_scores['test_score'])\n",
        "  perf_bests.append(best_performance)\n",
        "  perf_models.append(best_scores[\"estimator\"][bestModelIndex])\n",
        "  perf_model_names.append(best_embedding)\n",
        "  perf_alphas.append(best_alpha)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yx7UUbO38lL3",
        "outputId": "fc7b4516-bfeb-456f-dd7d-367e739967e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best performance for FG%: -1.4285666811730825e-05\n",
            "Used model ubigram_tfidf4\n",
            "Used alpha 1\n",
            "Best performance for PR: -0.07982089593018349\n",
            "Used model bigram_tfidf3\n",
            "Used alpha 0.05\n",
            "Best performance for 3P%: -0.12408383421538831\n",
            "Used model bigram_tfidf3\n",
            "Used alpha 0.001\n",
            "Best performance for PF: 0.0180742675141465\n",
            "Used model unigram_tfidf3\n",
            "Used alpha 1\n",
            "Best performance for PTS: 0.030634500299531464\n",
            "Used model ubigram_tfidf2\n",
            "Used alpha 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adaboosting Linear Regression"
      ],
      "metadata": {
        "id": "n-cmsCD28lW2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "perf_bests = []\n",
        "perf_models = []\n",
        "perf_model_names = []\n",
        "\n",
        "#num_estimators = list(range(0, 111, 5))\n",
        "#num_estimators[0] = 1\n",
        "num_estimators = [10, 25, 50, 75, 100]\n",
        "\n",
        "\n",
        "best_estimators = []\n",
        "best_features = []\n",
        "\n",
        "\n",
        "num_features = [\"sqrt\", \"log2\", \"special\"]\n",
        "\n",
        "\n",
        "\n",
        "for perf in Performance:\n",
        "  y = TextAndNBA.loc[TextAndNBA.index.isin(TrainIndex), f'{perf}'].values\n",
        "  best_performance = -10000000\n",
        "  best_scores = None\n",
        "  best_embedding = \"\"\n",
        "  best_esti = 0\n",
        "  best_feature = None\n",
        "\n",
        "  for num_feature in num_features:\n",
        "    #print(f\"Doing {num_feature}\")\n",
        "    for num_estimator in num_estimators:\n",
        "      #print(f\"Doing {num_estimator}\")\n",
        "      for embeddingType in ALL_DATA.keys():\n",
        "        X = ALL_DATA[embeddingType]\n",
        "\n",
        "        if num_feature == \"special\":\n",
        "          num_feature = int(X.shape[1] / 3)\n",
        "\n",
        "        sample_tree = DecisionTreeRegressor(max_features=num_feature)\n",
        "        adareg = AdaBoostRegressor(estimator = sample_tree, n_estimators= num_estimator)\n",
        "        scores = cross_validate(adareg, X, y, cv=10, return_estimator=True)\n",
        "        mean_performance = scores['test_score'].mean()\n",
        "        if mean_performance > best_performance:\n",
        "          best_performance = mean_performance\n",
        "          best_scores = scores\n",
        "          best_embedding = embeddingType\n",
        "          best_esti = num_estimator\n",
        "          best_feature = num_feature\n",
        "  print(f\"Best performance for {perf}: {best_performance}\")\n",
        "  print(f\"Used model {best_embedding}\")\n",
        "  print(f\"Best Estimator {best_esti}\")\n",
        "  print(f\"Best Feature {best_feature}\")\n",
        "\n",
        "\n",
        "  best_features.append(best_feature)\n",
        "  best_estimators.append(best_esti)\n",
        "  bestModelIndex = np.argmax(best_scores['test_score'])\n",
        "  perf_bests.append(best_performance)\n",
        "  perf_models.append(best_scores[\"estimator\"][bestModelIndex])\n",
        "  perf_model_names.append(best_embedding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULRVtK-HHtYG",
        "outputId": "4ea2751b-769b-41c3-f591-1938e916487f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best performance for FG%: 0.013459621159663704\n",
            "Used model ubigram_tfidf4\n",
            "Best Estimator 25\n",
            "Best Feature log2\n",
            "Best performance for PR: -0.07474189031916498\n",
            "Used model ubigram_tfidf4\n",
            "Best Estimator 100\n",
            "Best Feature 911\n",
            "Best performance for 3P%: -0.12146581565185113\n",
            "Used model unigram_tfidf3\n",
            "Best Estimator 100\n",
            "Best Feature sqrt\n",
            "Best performance for PF: 0.07319433983130606\n",
            "Used model unigram_tfidf5\n",
            "Best Estimator 50\n",
            "Best Feature sqrt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bgGn7t7JHtjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qf97utZrHtwW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}